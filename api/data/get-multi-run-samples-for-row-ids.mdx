---
title: Get Multi-Run Samples for Row IDs
openapi: post /projects/{project_id}/runs/prompts/rows/columnar
---

This endpoint retrieves detailed sample data for specific row IDs across multiple experiment runs. It's particularly useful for comparing how the same inputs perform across different model configurations, prompt templates, or parameter settings. The endpoint returns comprehensive information about each sample, including prompts, completions, and evaluation metrics.

## Path Parameters

| Parameter | Type | Description |
| --------- | ---- | ----------- |
| `project_id` | string (UUID) | The unique identifier of the project containing the runs |

## Request Body

| Field | Type | Description |
| ----- | ---- | ----------- |
| `run_ids` | array of strings | Required. List of run IDs to include in the comparison |
| `row_ids` | array of strings | Required. List of row IDs to retrieve |
| `include_metrics` | boolean | Optional. Whether to include evaluation metrics (default: false) |
| `include_metadata` | boolean | Optional. Whether to include additional metadata (default: false) |

### Example Request

```json
{
  "run_ids": ["run_12345", "run_67890"],
  "row_ids": ["sample_1", "sample_2", "sample_3"],
  "include_metrics": true,
  "include_metadata": true
}
```

## Response

The response contains detailed information about the requested samples across the specified runs.

### Example Response

```json
{
  "runs": [
    {
      "run_id": "run_12345",
      "run_name": "GPT-4 Baseline",
      "run_date": "2023-05-15T10:00:00Z",
      "model": "gpt-4",
      "samples": [
        {
          "row_id": "sample_1",
          "input_hash": "a1b2c3d4e5f6",
          "prompt": "Summarize the following article: [article text]",
          "completion": "The article discusses the impact of artificial intelligence on healthcare, highlighting three main areas: diagnosis, treatment planning, and administrative efficiency...",
          "metrics": {
            "accuracy_score": 0.92,
            "completeness_score": 0.88,
            "response_time": 1.8
          },
          "metadata": {
            "prompt_template": "Summarization Template v1",
            "tokens": 320,
            "temperature": 0.7
          }
        },
        {
          "row_id": "sample_2",
          "input_hash": "f6e5d4c3b2a1",
          "prompt": "Recommend products for a customer interested in: [customer preferences]",
          "completion": "Based on your interests, I recommend the following products: 1. Premium Wireless Headphones...",
          "metrics": {
            "relevance_score": 0.85,
            "diversity_score": 0.78,
            "response_time": 2.3
          },
          "metadata": {
            "prompt_template": "Product Recommendation v1",
            "tokens": 450,
            "temperature": 0.8
          }
        }
      ]
    },
    {
      "run_id": "run_67890",
      "run_name": "GPT-4 Optimized",
      "run_date": "2023-05-20T14:30:00Z",
      "model": "gpt-4",
      "samples": [
        {
          "row_id": "sample_3",
          "input_hash": "a1b2c3d4e5f6",
          "prompt": "Please provide a concise summary of: [article text]",
          "completion": "This article explores AI's healthcare impact, focusing on improved diagnostic accuracy (30% improvement in early detection), personalized treatment planning, and 40% reduction in administrative tasks...",
          "metrics": {
            "accuracy_score": 0.95,
            "completeness_score": 0.90,
            "response_time": 1.5
          },
          "metadata": {
            "prompt_template": "Summarization Template v2",
            "tokens": 280,
            "temperature": 0.5
          }
        },
        {
          "row_id": "sample_4",
          "input_hash": "f6e5d4c3b2a1",
          "prompt": "Based on the following preferences, suggest relevant products: [customer preferences]",
          "completion": "Here are 5 products that match your preferences: 1. Ultra Comfort Wireless Headphones...",
          "metrics": {
            "relevance_score": 0.92,
            "diversity_score": 0.85,
            "response_time": 1.9
          },
          "metadata": {
            "prompt_template": "Product Recommendation v2",
            "tokens": 380,
            "temperature": 0.6
          }
        }
      ]
    }
  ]
}
```

## Error Responses

| Status Code | Description |
| ----------- | ----------- |
| `404` | Project not found |
| `403` | Insufficient permissions to access the runs |
| `400` | Invalid request body or missing required parameters |

## Security

This endpoint requires authentication. You can authenticate using:

- An API key in the `Galileo-API-Key` header
- OAuth2 password flow
- HTTP Basic authentication

## Notes

- This endpoint is particularly useful for detailed A/B testing and comparing the performance of different model configurations
- The `input_hash` field helps identify the same input across different runs, enabling direct comparison
- Including metrics provides quantitative performance data for each sample, which is essential for objective comparison
- Including metadata provides context about the configuration used for each sample
- This endpoint pairs well with the "Get Multi-Run Sample IDs" endpoint, which can be used first to identify relevant row IDs
- For large datasets, consider retrieving samples in smaller batches to manage response size
- The detailed prompt and completion data allows for qualitative analysis alongside quantitative metrics