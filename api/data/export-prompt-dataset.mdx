---
title: Export Prompt Dataset
openapi: get /projects/{project_id}/runs/{run_id}/prompts/export_prompt_dataset
---

This endpoint allows you to export prompt data from a specific experiment run as a structured dataset. The exported dataset contains all prompts, completions, and associated metadata from the run, making it easy to analyze, share, or use in other systems. This is particularly useful for creating training datasets, performing offline analysis, or archiving experiment results.

## Path Parameters

| Parameter | Type | Description |
| --------- | ---- | ----------- |
| `project_id` | string (UUID) | The unique identifier of the project containing the run |
| `run_id` | string (UUID) | The unique identifier of the experiment run to export |

## Query Parameters

| Parameter | Type | Description |
| --------- | ---- | ----------- |
| `format` | string | Optional. The export format: "json" (default), "csv", or "jsonl" |
| `include_metadata` | boolean | Optional. Whether to include additional metadata in the export (default: true) |
| `filter` | string | Optional. JSON-encoded filter criteria to select specific prompts |

## Response

The response is a file download in the requested format containing the prompt dataset.

### JSON Format Example

```json
{
  "metadata": {
    "run_id": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
    "run_name": "Production Test Run",
    "export_date": "2023-06-15T14:30:00Z",
    "prompt_count": 250
  },
  "prompts": [
    {
      "id": "prompt_123456",
      "text": "Summarize the following article: ...",
      "completion": "The article discusses...",
      "timestamp": "2023-06-14T10:15:00Z",
      "metadata": {
        "model": "gpt-4",
        "temperature": 0.7,
        "tokens": 350
      }
    },
    // Additional prompts...
  ]
}
```

## Error Responses

| Status Code | Description |
| ----------- | ----------- |
| `404` | Project or run not found |
| `403` | Insufficient permissions to access the run |
| `400` | Invalid format or filter parameter |

## Security

This endpoint requires authentication. You can authenticate using:

- An API key in the `Galileo-API-Key` header
- OAuth2 password flow
- HTTP Basic authentication

## Notes

- Large datasets may take longer to generate and download
- For very large datasets, consider using filters to reduce the size
- The exported dataset includes all prompt versions used in the run
- Metadata includes information about models, parameters, and performance metrics when available
- The dataset can be directly imported into many machine learning frameworks and analysis tools