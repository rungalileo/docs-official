---
title: Experiments
icon: "flask"
---

Galileo Experiments allow you to evaluate and improve your LLM applications by running tests against datasets and measuring performance using various metrics.

## Running an Experiment with a Runner Function

```typescript
import { runExperiment } from 'galileo-experimental';
import { OpenAI } from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const runner = async (input) => {
  const result = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ content: `Say hello ${input['name']}!`, role: 'user' }]
  });
  return result;
};

await runExperiment({
  name: `Test Experiment`,
  datasetName: 'names',
  runner: runner,
  metrics: ['output_tone'],
  projectName: 'my-project'
});
```

## Creating a Prompt Template

```typescript
import { createPromptTemplate } from 'galileo-experimental';

const template = await createPromptTemplate({
  template: [{ role: 'user', content: 'Say "Hello, {name}"!' }],
  projectName: 'my-project',
  name: `Hello name prompt`
});
```

## Running an Experiment with a Prompt Template

```typescript
import {
  getPromptTemplate,
  getDataset,
  runExperiment
} from 'galileo-experimental';

const template = await getPromptTemplate(
  'my-project',
  'Hello name prompt'
);

const dataset = await getDataset(undefined, 'names');

await runExperiment({
  name: `Test Experiment`,
  dataset: dataset,
  promptTemplate: template,
  metrics: ['output_tone'],
  projectName: 'my-project'
});
```

## Running an Experiment with a Custom Dataset

```typescript
import { runExperiment } from 'galileo-experimental';
import { OpenAI } from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const dataset = [
  { name: 'John' },
  { name: 'Jane' },
  { name: 'Bob' },
  { name: 'Alice' }
];

const runner = async (input) => {
  const result = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ content: `Say hello ${input['name']}!`, role: 'user' }]
  });
  return result;
};

await runExperiment({
  name: `Test Experiment`,
  dataset: dataset,
  runner: runner,
  metrics: ['output_tone'],
  projectName: 'my-project'
});
```

## API Reference

### runExperiment

```typescript
async function runExperiment(options: {
  name: string;
  dataset?: any[];
  datasetName?: string;
  runner?: (input: any) => Promise<any>;
  promptTemplate?: PromptTemplate;
  metrics?: string[];
  projectName: string;
}): Promise<string>
```

Runs an experiment.

#### Parameters

- `options`: Configuration options for the experiment
  - `name`: The name of the experiment
  - `dataset`: (Optional) An array of data objects to use for the experiment
  - `datasetName`: (Optional) The name of a dataset to use for the experiment
  - `runner`: (Optional) A function that takes an input and returns a result
  - `promptTemplate`: (Optional) A prompt template to use for the experiment
  - `metrics`: (Optional) An array of metric names to use for evaluation
  - `projectName`: The project to run the experiment in

#### Returns

A Promise that resolves to a URL where you can view the experiment results. 