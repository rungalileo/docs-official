---
title: OpenAI Wrapper
icon: "openai"
---

# OpenAI Wrapper

The OpenAI wrapper provides a simple way to automatically log all OpenAI API calls to Galileo. It wraps the official OpenAI Node.js client and intercepts all API calls to log them.

## Installation

```bash
npm install galileo-sdk openai
# or
yarn add galileo-sdk openai
```

## Usage

```typescript
import { OpenAI } from "openai";
import { wrapOpenAI } from "galileo/wrappers";

// Create a wrapped OpenAI client
const openai = wrapOpenAI(new OpenAI({ apiKey: "your-openai-api-key" }));

// Use the wrapped client as you normally would
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [{ role: "user", content: "Say hello world!" }],
});

console.log(response.choices[0].message.content);
```

## Advanced Usage

### With Context Manager

You can use the OpenAI wrapper with the `withGalileo` context manager to create a trace with multiple spans:

```typescript
import { OpenAI } from "openai";
import { withGalileo } from "galileo";
import { wrapOpenAI } from "galileo/wrappers";

const openai = wrapOpenAI(new OpenAI({ apiKey: "your-openai-api-key" }));

withGalileo({ project: "my-project", logStream: "my-log-stream" }, async () => {
  // First LLM call
  const response1 = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [{ role: "user", content: "What is the capital of France?" }],
  });
  
  // Second LLM call
  const response2 = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [
      { role: "user", content: "What is the capital of Germany?" }
    ],
  });
  
  return {
    france: response1.choices[0].message.content,
    germany: response2.choices[0].message.content
  };
});
```

### With Observe Wrapper

You can use the OpenAI wrapper with the `observe` wrapper to create a workflow span with nested LLM calls:

```typescript
import { OpenAI } from "openai";
import { observe } from "galileo";
import { wrapOpenAI } from "galileo/wrappers";

const openai = wrapOpenAI(new OpenAI({ apiKey: "your-openai-api-key" }));

const getCapital = async (country: string) => {
  const response = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [{ role: "user", content: `What is the capital of ${country}?` }],
  });
  return response.choices[0].message.content;
};

const getCapitals = async () => observe(
  { spanType: "workflow", name: "getCapitals" },
  async () => {
    const franceCapital = await getCapital("France");
    const germanyCapital = await getCapital("Germany");
    return { france: franceCapital, germany: germanyCapital };
  }
);

const result = await getCapitals();
console.log(result);
```

## API Reference

### wrapOpenAI

```typescript
function wrapOpenAI(client: OpenAI, options?: WrapperOptions): OpenAI
```

Wraps an OpenAI client instance to automatically log all API calls to Galileo.

#### Parameters

- `client`: An instance of the OpenAI client
- `options`: (Optional) Configuration options for the wrapper
  - `project`: The project to log to (overrides environment variable)
  - `logStream`: The log stream to log to (overrides environment variable)

#### Returns

A wrapped OpenAI client instance that automatically logs all API calls to Galileo. 