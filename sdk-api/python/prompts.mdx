---
title: Prompts
icon: "lightbulb"
description: Create and use a prompt template
---

Prompt templates in Galileo allow you to create, version, and reuse prompts across your application. This is particularly useful for standardizing prompts and running experiments with different prompt variations.

## Creating a Prompt Template

You can create a prompt template using the `create_prompt_template` function:

```python
from galileo.prompts import create_prompt_template
from galileo.resources.models import Message, MessageRole

# Create a prompt template with system and user messages
prompt_template = create_prompt_template(
    name="storyteller-prompt",
    project="my-project",
    messages=[
        Message(role=MessageRole.SYSTEM, content="You are a great storyteller."),
        Message(role=MessageRole.USER, content="Please write a short story about the following topic: {topic}")
    ]
)
```

## Getting an Existing Prompt Template

You can retrieve an existing prompt template using the `get_prompt_template` function:

```python
from galileo.prompts import get_prompt_template

# Get an existing prompt template
prompt_template = get_prompt_template(
    project="my-project",
    name="storyteller-prompt"
)
```

## Using a Prompt Template with OpenAI

Once you have a prompt template, you can use it with the OpenAI wrapper:

```python
import os
from galileo import openai
from galileo.prompts import get_prompt_template

# Initialize the OpenAI client
client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# Get an existing prompt template
prompt = get_prompt_template(
    project="my-project",
    name="storyteller-prompt"
)

# Prepare the data for the template variables
data = {
    "topic": "Nuclear Physics"
}

# Use the prompt template with OpenAI
response = client.chat.completions.create(
    model="gpt-4o",
    messages=prompt.with_data(data).to_messages()
)

print(response.choices[0].message.content)
```

## Using Prompt Templates in Experiments

Prompt templates are particularly useful for running experiments to compare different prompt variations:

```python
from galileo.datasets import get_dataset
from galileo.experiments import run_experiment
from galileo.prompts import get_prompt_template

# Get an existing prompt template
prompt = get_prompt_template(
    project="my-project",
    name="storyteller-prompt"
)

# Run an experiment with the prompt template
results = run_experiment(
    "my-experiment",
    dataset=get_dataset(name="storyteller-dataset"),
    prompt=prompt,
    metrics=["correctness"],
    project="my-project",
)
```

## Creating a New Prompt Template if Not Exists

You can check if a prompt template exists and create it if it doesn't:

```python
from galileo.prompts import get_prompt_template, create_prompt_template
from galileo.resources.models import Message, MessageRole

# Try to get an existing prompt template
prompt = get_prompt_template(
    project="my-project",
    name="storyteller-prompt"
)

# If the prompt doesn't exist, create it
if prompt is None:
    prompt = create_prompt_template(
        name="storyteller-prompt",
        project="my-project",
        messages=[
            Message(role=MessageRole.SYSTEM, content="You are a great storyteller."),
            Message(role=MessageRole.USER, content="Please write a short story about the following topic: {topic}")
        ]
    )
```

## Best Practices

1. **Use descriptive names**: Choose clear, descriptive names for your prompt templates to make them easy to find and understand.

2. **Version your prompts**: Create new versions of prompts when making significant changes to track performance over time.

3. **Use template variables**: Use template variables (like `{topic}`) to make your prompts more flexible and reusable.

4. **Test different variations**: Use experiments to test different prompt variations and see which performs best.

5. **Include system messages**: Use system messages to set the tone and context for the LLM.

## Related Resources

- [Experiments](./experiments) - Running experiments with prompt templates
- [Datasets](./experimentation/datasets) - Creating and managing datasets for experiments
- [OpenAI Wrapper](./wrappers/openai) - Using the OpenAI wrapper with prompt templates
