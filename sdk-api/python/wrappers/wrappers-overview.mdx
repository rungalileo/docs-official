---
title: Overview
---

Galileo wrappers automatically capture prompts, responses, and performance metrics without requiring you to add explicit logging code throughout your application.

Just import the wrapper anywhere you were using the original library (ex. openai)!

## Available Wrappers

Galileo currently supports the following wrappers:

- [**OpenAI Wrapper**](./openai) - A drop-in replacement for the OpenAI library that automatically logs all prompts, responses, and statistics.
- [**LangChain Integration**](./langchain) - A callback-based integration for LangChain that logs all LLM interactions within your LangChain workflows.

## Alternative Methods of Logging

If you're using an LLM library that doesn't have a dedicated Galileo wrapper, you can still log your application using:

1. **The `@log` Decorator** - Add the `@log` decorator to functions that call LLMs to automatically capture inputs and outputs.
2. **Direct Use of the `GalileoLogger` Class** - For more control, you can use the base logger class directly.

For detailed information on these alternative logging methods, see the [Python SDK Overview](../reference).
