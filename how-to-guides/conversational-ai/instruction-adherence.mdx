---
title: Handling Ignored Instructions
description: Learn how to handle ignored instructions and ensure that your AI models follow your instructions.
---

import { Screenshot } from '/snippets/Screenshot.mdx';

When a model ignores instructions, it generates responses that deviate from the provided prompt structure, missing key details or adding extraneous information. This can lead to misleading, unhelpful, or non-compliant outputs.

## Setup

In this example, we'll use the `gpt-4o` model to generate a response to for a simple prompt. We'll enable the `instruction_adherence` metric to monitor the model's adherence to the prompt.

```python 
import os
from galileo import openai # The Galileo OpenAI client wrapper is all you need!
from dotenv import load_dotenv
load_dotenv()

client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

prompt = f"Explain the following topic succinctly: Newton's First Law"
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "system", "content": prompt}],
)
print(response.choices[0].message.content.strip())
```


### What Showed Up in Metrics:
When we examine the metric Instruction Adherence metric, we see that the model did not really follow the instructions in the prompt.
To understand why Galileo flagged this, we can review the explanation:

{/* Screenshot: Instruction Adherence Metrics - Before Optimization */}
<Screenshot
  alt="Instruction adherence metrics dashboard before applying optimization techniques"
  placeholder="Add screenshot of instruction adherence metrics before optimization"
  caption="Instruction Adherence Metrics - Before Optimization"
/>

As shown in the dashboard above, the instruction adherence score is low, indicating that our prompt wasn't followed correctly.

<Card>
<ResponseField name="Metric Explanation">
`The instruction provided was to 'Explain the following topic succinctly: Newton's first law'.   
The response begins by defining Newton's First Law and provides a clear explanation of the concept of inertia. However, the response is lengthy and provides more detail than the word 'succinctly' implies. While it does effectively cover the essence of the topic, it could be more concise to align better with the instruction.  Thus, while informative, the response does not fully adhere to the request for a succinct explanation.`
</ResponseField>
</Card>


### What Went Wrong?
As the explanation indicates, the main reason the model did not follow the instructions is that the prompt is too vague. The prompt does not provide enough information about what constitutes a "succinct" explanation. 

{/* Screenshot: Prompt Perplexity Visualization */}
<Screenshot
  alt="Visualization of prompt perplexity metrics and analysis"
  placeholder="Add screenshot of prompt perplexity visualization"
  caption="Prompt Perplexity Visualization"
/>

The perplexity visualization above shows how ambiguous terms like "succinctly" can lead to inconsistent interpretations by the model, resulting in responses that don't match our expectations.


## The Solution
In order to fix this, we can modify the prompt to provide more specific instructions:

{/* Screenshot: Adherence Configuration Panel */}
<Screenshot
  alt="Configuration panel showing available settings for instruction adherence"
  placeholder="Add screenshot of adherence configuration panel"
  caption="Adherence Configuration Panel"
/>

Using the configuration panel shown above, we can set up specific parameters for instruction adherence monitoring. Now, let's update our prompt with clearer instructions:

<CodeGroup>
```python Python
prompt = """
	1.	Explain Newton's First Law in one sentence of no more than fifteen (15) words.
	2.	Do not add any additional sentences, examples, parentheses, bullet points, or further clarifications.
	3.	Your answer must be exactly one sentence and must not exceed 15 words.
"""
```

```typescript TypeScript
const prompt = `
	1.	Explain Newton's First Law in one sentence of no more than fifteen (15) words.
	2.	Do not add any additional sentences, examples, parentheses, bullet points, or further clarifications.
	3.	Your answer must be exactly one sentence and must not exceed 15 words.
`;
```
</CodeGroup>

In this updated prompt, we gave the model more specific instructions about what constitutes a "succinct" explanation. We worded the prompt in three distinct variations to eliminate any ambiguity.

If we run the application again, we see that the model now follows the instructions more closely:

```
An object remains at rest or in uniform motion unless acted upon by a net force.
```

Now, our instruction adherence metric jumps to 100.00%!

{/* Screenshot: Instruction Adherence Metrics - After Optimization */}
<Screenshot
  alt="Instruction adherence metrics dashboard after applying optimization techniques, showing improvements"
  placeholder="Add screenshot of instruction adherence metrics after optimization"
  caption="Instruction Adherence Metrics - After Optimization"
/>

As demonstrated in the metrics dashboard above, our optimized prompt with specific, unambiguous instructions resulted in perfect adherence to our requirements. The model now produces exactly what we asked for: a concise, single-sentence explanation within the specified word limit.

By monitoring instruction adherence and iteratively improving your prompts based on the metrics, you can ensure your AI models consistently follow instructions as intended.