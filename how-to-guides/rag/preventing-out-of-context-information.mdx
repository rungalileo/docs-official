---
title: Preventing Out of Context Information
description: Learn how to prevent out of context information from being generated by your AI models.
icon: person-digging
---

If a model generates responses that include information not found in the retrieved context, it introduces closed-domain hallucinations. This means the model is making up facts rather than relying on retrieved information, leading to misinformation and reduced trust.

## What Went Wrong?

* **What We Did Wrong:**  
  * Retrieved documents contained irrelevant information.  
  * The model overgeneralized or extrapolated beyond what was retrieved.  
  * The retrieval pipeline was returning too many noisy or loosely related chunks.  
* **How It Showed Up in Metrics:**  
  * **Low Context Adherence**: The model included information not present in the retrieved documents.  
  * **High Chunk Attribution but Low Chunk Utilization**: The model referenced retrieved data but incorporated only small portions of it.

### Example of the Bad Setup

**User Query:** "What year was the Eiffel Tower completed?" 

**Retrieved Context:** "The Eiffel Tower is an iron lattice tower located in Paris, France. It was designed by Gustave Eiffel." 

**Model Response:** "The Eiffel Tower was completed in 1889 and is the most visited paid monument in the world."

## Improvements and Solutions

<Steps>
<Step title="Improve Context Selection">

* Apply **better chunking strategies** to ensure context retrieval is more structured and relevant.  
  * Use **overlapping sliding windows** to maintain continuity in extracted information.  
  * Optimize chunk sizes to prevent truncation of important details.  
* **Switch to a more powerful embedding model** for retrieval to improve similarity matching.  
* Implement **re-ranking algorithms** to prioritize the most relevant chunks from retrieved data.  
  * Use **cross-encoders** to refine ranking.  
  * Apply **learned ranking models** to adjust chunk importance dynamically.
</Step>
<Step title="Use Hybrid Retrieval Techniques">

* Combine **dense vector search** (embeddings) with **sparse retrieval** (BM25, TF-IDF) for better precision.  
* Use **query expansion techniques** to reformulate the user’s query to better match retrieved documents.  
* Tune similarity thresholds to eliminate loosely related retrieved data.
</Step>
<Step title="Enforce Context Adherence in Prompts">

* Modify prompts to emphasize strict reliance on provided context:

```
Instruction: Only use the retrieved context to answer the question. If the answer is not found, state 'I don’t know.'
```

* Penalize generations that introduce out-of-context information by fine-tuning the model with contrastive learning techniques.
</Step>
<Step title="Validate Responses for Adherence">

* Use **Context Adherence Plus** to generate explanations for why responses are not contextually aligned.  
* Flag responses with adherence scores below a threshold for human review.  
* Apply **post-processing filters** to remove non-contextual information before presenting responses to users.
</Step>
</Steps>