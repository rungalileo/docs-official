import React from 'react';
export const MetricCategories = () => (
  <div>
    <table style={{ width: "100%", borderCollapse: "collapse", textAlign: "left" }}>
      <thead>
        <tr>
          <th style={{ textAlign: "left", paddingBottom: "8px", paddingRight: "24px" }}>Category</th>
          <th style={{ textAlign: "left", paddingBottom: "8px" }}>Description</th>
          <th style={{ textAlign: "left", paddingBottom: "8px" }}>When to Use</th>
          <th style={{ textAlign: "left", paddingBottom: "8px" }}>Example Use Cases</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style={{ paddingRight: "24px" }}><a href="/concepts/metrics/agentic">Agentic</a></td>
          <td>Metrics that evaluate how effectively AI agents perform tasks, use tools, and progress toward goals.</td>
          <td>When building and optimizing AI systems that take actions, make decisions, or use tools to accomplish tasks.</td>
          <td>
            <ul>
              <li>Evaluating a travel planning agent's ability to book complete itineraries</li>
              <li>Assessing a coding assistant's appropriate use of APIs and libraries</li>
              <li>Measuring a data analysis agent's tool selection effectiveness</li>
            </ul>
          </td>
        </tr>
        <tr>
          <td style={{ paddingRight: "24px" }}><a href="/concepts/metrics/response-quality">Response Quality</a></td>
          <td>Metrics that assess the accuracy, completeness, relevance, and overall quality of AI-generated responses.</td>
          <td>When evaluating how well AI systems answer questions, follow instructions, or provide information based on context.</td>
          <td>
            <ul>
              <li>Measuring factual accuracy in a medical information system</li>
              <li>Evaluating how well a RAG system uses retrieved information</li>
              <li>Assessing if customer service responses address all parts of a query</li>
            </ul>
          </td>
        </tr>
        <tr>
          <td style={{ paddingRight: "24px" }}><a href="/concepts/metrics/safety-and-compliance">Safety and Compliance</a></td>
          <td>Metrics that identify potential risks, harmful content, bias, or privacy concerns in AI interactions.</td>
          <td>When ensuring AI systems meet regulatory requirements, protect user privacy, and avoid generating harmful or biased content.</td>
          <td>
            <ul>
              <li>Detecting PII in healthcare chatbot conversations</li>
              <li>Identifying potential prompt injection attacks in public-facing systems</li>
              <li>Measuring bias in hiring or loan approval recommendation systems</li>
            </ul>
          </td>
        </tr>
        <tr>
          <td style={{ paddingRight: "24px" }}><a href="/concepts/metrics/expression-and-readability">Expression and Readability</a></td>
          <td>Metrics that evaluate the style, tone, clarity, and overall presentation of AI-generated content.</td>
          <td>When the format, tone, and presentation of AI outputs are important for user experience or brand consistency.</td>
          <td>
            <ul>
              <li>Ensuring a luxury brand chatbot maintains a sophisticated tone</li>
              <li>Verifying educational content is presented at the appropriate reading level</li>
              <li>Measuring clarity and conciseness in technical documentation generation</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
);