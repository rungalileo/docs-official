```bash Python
import os
from galileo import galileo_context, GalileoLogger # The Galileo context manager
from galileo.openai import openai # The Galileo OpenAI client wrapper
from dotenv import load_dotenv
load_dotenv()

# Initialize the OpenAI client using the Galileo wrapper and your OpenAI API key
client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# The Galileo context manager will automatically create a trace and flush the logs when exiting
with galileo_context():
    prompt = f"Explain the following topic succinctly: Newton's First Law"
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": prompt}],
    )
    print(response.choices[0].message.content.strip())
```

```bash Typescript
TYPESCRIPT_CODEimport { OpenAI } from "openai";
import { init, flush, wrapOpenAI } from "galileo";
import dotenv from 'dotenv';
dotenv.config();

// Initialize the OpenAI client using the Galileo wrapper and your OpenAI API key
const openai = wrapOpenAI(new OpenAI({ apiKey: process.env.OPENAI_API_KEY }));

# The Galileo context manager will automatically create a trace and flush the logs when exiting
init({
  projectName: "my-project",
  logStreamName: "development"
});

const prompt = "Explain the following topic succinctly: Newton's First Law";
await openai.chat.completions.create({
 model: "gpt-4o",
 messages: [{ content: prompt, role: "user" }],
});

// Flush logs before exiting
await flush();
```