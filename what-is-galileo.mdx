---
title: What is Galileo?
icon: "house"
---
import { DefinitionCard } from '/snippets/components/definition-card.mdx';

Galileo is an **AI evaluation and monitoring platform** built specifically for developers building complex AI applications. It addresses the inherent challenges of generative AI—where the same input can yield different outputs—making it hard to pin down quality and troubleshoot issues.

<CardGroup cols={1}>
  <Card title="Identify & Fix Issues Fast" icon="bolt" horizontal>
    Quickly pinpoint problematic responses with comprehensive metrics across multiple dimensions. Galileo's detailed traces and spans help you diagnose root causes and implement targeted fixes, reducing debugging time from days to minutes.
  </Card>
  <Card title="Ensure Consistent Quality" icon="shield-check" horizontal>
    Monitor your AI application's performance with automated quality checks that detect regressions before they impact users. Set custom thresholds for metrics like completeness, correctness, and safety to maintain consistent quality standards as your application evolves.
  </Card>
  <Card title="Optimize with Confidence" icon="chart-line" horizontal>
    Make data-driven decisions when optimizing prompts, models, and retrieval systems. Galileo's experimentation framework lets you compare different approaches side-by-side with quantifiable metrics, so you can confidently implement changes that improve user experience.
  </Card>
</CardGroup>

## The Challenge

<DefinitionCard>
  **Generative AI** introduces a unique set of challenges that traditional testing methods _simply cannot address_.
</DefinitionCard>

In this space, even when you feed the exact same input into your system, you might receive a range of different outputs, complicating the process of defining what **"correct" even means**. This variability makes it difficult to establish consistent benchmarks and increases the complexity of debugging when something goes awry.

Moreover, as the underlying models and data are updated and evolve, application behavior can shift unexpectedly, rendering previously successful tests obsolete. This dynamic environment requires tools that not only measure performance accurately but also adapt to ongoing changes, all while providing clear, actionable insights into the AI's behavior across its entire lifecycle.

## How Galileo Helps

<CardGroup cols={2}>
  <Card title="Data-Driven Metrics" icon="chart-bar">
    Automated, token-level quality checks to reveal nuanced performance insights. Understand exactly how your AI is performing with detailed analytics.
  </Card>
  <Card title="Configurable Regression Detection" icon="radar">
    Tolerance thresholds that filter out minor fluctuations, highlighting significant issues. Get alerted only when changes matter to your application.
  </Card>
  <Card title="Integrated Feedback" icon="comments">
    Seamlessly incorporates real-world insights into your development cycle. Turn user feedback into actionable improvements for your AI system.
  </Card>
  <Card title="End-to-End Visibility" icon="eye">
    Clear, visual tracking of your AI application's performance—from prompt design to production. Monitor the complete lifecycle in one unified interface.
  </Card>
</CardGroup>

## Getting Started

<CardGroup cols={1}>
  <Card title="Get Started!" icon="bolt" horizontal>
    Get up and running with a few lines of code.
  </Card>  
</CardGroup>
