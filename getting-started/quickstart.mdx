---
title: "Getting Started with Galileo"
icon: "code"
syncTabs: true
---


Welcome to Galileo! This quickstart guide will walk you through setting up your first AI evaluation in minutes. You'll learn how to identify and fix common issues in AI responses using Galileo's powerful metrics and insights.

### **What You'll Learn**
* Set up and run an AI evaluation with Galileo in less than 5 minutes
* Interpret key metrics to identify response quality issues
* Apply prompt engineering techniques to fix common AI response problems
* Understand how Galileo helps you build more reliable AI applications

<Steps>
<Step title="Install Dependencies">

Install the Galileo package:
<CodeGroup>
```bash Python
pip install galileo
```

```bash TypeScript
npm install galileo
```
</CodeGroup>
</Step>

<Step title="Set Up Environment Variables">

Create a `.env` file in the project directory and add the following credentials:
```text
GALILEO_API_KEY="https://console.experimental.rungalileo.io"
GALILEO_PROJECT=
GALILEO_LOG_STREAM=
OPENAI_API_KEY=your-api-key-here
```
</Step>

<Step title="Create a Project Directory">

Create a project directory and add the following files:
<CodeGroup>
```python Python
/your_project_directory
â”‚â”€â”€ app.py
â”‚â”€â”€ .env
```

```typescript TypeScript
/your_project_directory
â”‚â”€â”€ app.ts
â”‚â”€â”€ .env
```
</CodeGroup>
</Step>

<Step title="Application Code">
<CodeGroup>
```python Python
import os
from galileo import openai # The Galileo OpenAI client wrapper is all you need!
from dotenv import load_dotenv
load_dotenv()

client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

prompt = f"Explain the following topic succinctly: Newton's First Law"
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "system", "content": prompt}],
)
print(response.choices[0].message.content.strip())
```

```typescript TypeScript
import { OpenAI } from "openai";
import { wrapOpenAI } from "galileo/wrappers";

const openai = wrapOpenAI(new OpenAI(apiKey=""));
const prompt = "Explain the following topic succinctly: Newton's First Law";
await openai.chat.completions.create({
 model: "gpt-4o",
 messages: [{ content: prompt, role: "user" }],
});
```
</CodeGroup>
</Step>

<Step title="Run the Application">

To run this simple application, simply run the following:
<CodeGroup>
```bash Python
python app.py
```

```bash TypeScript
node app.ts
```
</CodeGroup>
</Step>

<Step title="Analyze the results">

Check your terminal for the output or head over to the Galileo console for extra details like cost and latency.

[INSERT SCREENSHOT]
<Card>
<ResponseField name="The Model's Response">
`Newton's First Law, often referred to as the Law of Inertia, states that an object will remain at rest, or in uniform motion in a straight line, unless acted upon by a net external force. This means that if an object is not influenced by any external forces, it will maintain its current state of motion. Essentially, this law emphasizes the concept of inertia, which is the natural tendency of objects to resist changes in their motion. It forms the foundation for classical mechanics, outlining the behavior of objects when forces are not in play.`
</ResponseField>
</Card>
</Step>


</Steps>
<Note>Your application is now connected to Galileo ðŸŽ‰! You can continue to explore on your own or read more about improving the prompt.</Note>

### **Fixing prompt issues**

If you examine the results we got for our first run, you'll see that the model's response is not exactly what we asked for. We're using **<Tooltip tip="Measures whether a model followed or adhered to the system or prompt instructions when generating a response. Instruction Adherence is a good way to uncover hallucinations where the model is ignoring instructions.">instruction adherence</Tooltip>** to check how well our model follows directions.

#### **What Happened?**
* We asked for a **succinct** explanation.
* The model gave a **detailed** answer instead. ðŸ˜¢
* Our **instruction adherence metric was 0.00%**, meaning we need to tweak our prompt. 

To understand **why** our instruction adherence metric was so low we can look at the **metric explanation**: 

[INSERT SCREENSHOT]
<Card>
<ResponseField name="Metric Explanation">
`The instruction provided was to 'Explain the following topic succinctly: Newton's first law'.   
The response begins by defining Newton's First Law and provides a clear explanation of the concept of inertia. However, the response is lengthy and provides more detail than the word 'succinctly' implies. While it does effectively cover the essence of the topic, it could be more concise to align better with the instruction.  Thus, while informative, the response does not fully adhere to the request for a succinct explanation.`
</ResponseField>
</Card>

This explanation correctly points out that the answer we got wasn't exactly succinct. So, let's modify our prompt to fix this. We'll make sure to explain *what succinctness means for us*:
<CodeGroup>
```python Python
prompt = """
	1.	Explain Newton's First Law in one sentence of no more than fifteen (15) words.
	2.	Do not add any additional sentences, examples, parentheses, bullet points, or further clarifications.
	3.	Your answer must be exactly one sentence and must not exceed 15 words.
"""
```

```typescript TypeScript
const prompt = `
	1.	Explain Newton's First Law in one sentence of no more than fifteen (15) words.
	2.	Do not add any additional sentences, examples, parentheses, bullet points, or further clarifications.
	3.	Your answer must be exactly one sentence and must not exceed 15 words.
`;
```
</CodeGroup>

Running this again, our results will look much more concise:

Now, our **instruction adherence metric jumps to 100.00%**! ðŸŽ‰

[INSERT SCREENSHOT]

## **What's Next**

Now that you've completed your first evaluation, explore these resources to build better AI applications:


* **SDKs**: Integrate Galileo with [Python](/sdk-api/python/reference) or [TypeScript](/sdk-api/typescript/reference)
* **Application Guides**: Optimize [Conversational AI](/how-to-guides/conversational-ai/instruction-adherence), [RAG Systems](/how-to-guides/rag/preventing-out-of-context-information), or [AI Agents](/how-to-guides/agentic-ai/optimizing-multi-step-task-execution)
* **Advanced Features**: Run [Experiments](/cookbooks/features/experimentation/creating-experiments), create [Custom Metrics](/cookbooks/features/insights/custom-metric-creation), and detect [Failure Modes](/cookbooks/features/insights/failure-mode-detection)

Continue your journey with our comprehensive [How-to Guides](/how-to-guides/overview).
