---
title: Safety and Compliance Metrics
description: Identify risks, harmful content, and compliance issues in your AI with Galileo's safety and compliance metrics.
---

# Safety and Compliance Metrics Overview

Safety and compliance metrics help you ensure your AI systems are safe, fair, and meet regulatory requirements. These metrics are essential for protecting users, avoiding harmful outputs, and building trust in your AI applications.

Use these metrics when you want to:
- Detect and prevent the exposure of sensitive or personally identifiable information (PII).
- Identify and filter out toxic, biased, or inappropriate content.
- Guard against prompt injection attacks and other security risks.
- Ensure your AI meets industry or legal compliance standards.

Our safety and compliance metrics include:

- **PII / CPNI / PHI:** Identifies personally identifiable or sensitive information in prompts and responses.  
  [Learn more →](pii)
- **Prompt Injection:** Detects attempts to manipulate the model through malicious prompts.  
  [Learn more →](prompt-injection)
- **Sexism / Bias:** Detects gender-based bias or discriminatory content.  
  [Learn more →](sexism)
- **Toxicity:** Identifies harmful, offensive, or inappropriate content.  
  [Learn more →](toxicity)

Below is a quick reference table of all safety and compliance metrics:

<SafetyAndComplianceMetrics />

---

## Next Steps

- [Back to Metrics Overview](../overview)
- [Compare all metrics](../metric-comparison)
