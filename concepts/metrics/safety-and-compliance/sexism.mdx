---
title: Sexism
description: Detect and prevent sexist content in AI systems using Galileo's Sexism Metric to identify and mitigate biased responses.
---

import { Scale } from '/snippets/components/scale.mdx';
import { DefinitionCard } from '/snippets/components/definition-card.mdx';

<DefinitionCard>
  <strong>Sexism Detection</strong> flags whether a response contains sexist content. Output is a binary classification of whether a response is sexist or not.
</DefinitionCard>

### Calculation Method
Sexism detection is computed through a specialized process:

<Steps>
  <Step title="We leverage a Small Language Model (SLM) trained on open-source and internal datasets." />
  <Step title="Our model's accuracy on the Explainable Detection of Online Sexism dataset (open-source) is 83%." />
</Steps>

## Optimizing Your AI System

<Card>
  <div style={{display: 'flex', alignItems: 'center', gap: '0.5rem', marginBottom: '0.75rem'}}>
    <div style={{fontSize: '1.25rem', color: 'var(--primary-color)'}}>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
        <path d="M12 20h9"></path><path d="M16.5 3.5a2.121 2.121 0 0 1 3 3L7 19l-4 1 1-4L16.5 3.5z"></path>
      </svg>
    </div>
    <h3 style={{margin: 0, fontSize: '1.25rem', fontWeight: '600'}}>Addressing Sexism in Your System</h3>
  </div>
  
  When sexist content is detected in your system, consider these approaches:
      
  <div style={{marginTop: '1rem', paddingTop: '0.75rem', borderTop: '1px solid rgba(209, 213, 219, 0.33)'}}>
    <strong>Implement guardrails:</strong> Flag responses before being served to prevent future occurrences.
  </div>
  
  <div style={{marginTop: '0.75rem', paddingTop: '0.75rem', borderTop: '1px solid rgba(209, 213, 219, 0.33)'}}>
    <strong>Fine-tune models:</strong> Adjust model behavior to reduce sexist outputs.
  </div>
</Card>

<Note>
Identify responses that contain sexist comments and take preventive measures to ensure fair and unbiased AI interactions.
</Note>

