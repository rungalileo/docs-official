---
title: Instruction Adherence
description: Assess instruction adherence in AI outputs using Galileo Guardrail Metrics to ensure prompt-driven models generate precise and actionable results.
---

**Instruction Adherence** measures whether a model followed or adhered to the system or prompt instructions when generating a response.

## How it Works

Instruction Adherence is a continuous metric ranging from 0 to 1:
- A value of 1 (or close to 1) indicates high adherence - the model followed its instructions when generating its response
- A value of 0 (or close to 0) indicates low adherence - the model went off-script and ignored parts of its instructions

This metric is particularly valuable for uncovering hallucinations where the model is ignoring instructions, which can lead to responses that don't meet user requirements or business rules.

## Calculation Method

Instruction Adherence is computed through a multi-step process:
- Sending additional requests to OpenAI's GPT4o
- Using a carefully engineered chain-of-thought prompt that asks the model to judge whether the response adhered to instructions
- Requesting multiple distinct responses to this prompt
- Each evaluation produces an explanation along with a final judgment: yes or no
- The final score is the fraction of "yes" responses divided by the total number of responses

We also surface one of the generated explanations, always choosing one that aligns with the majority judgment among the responses.

<Note>
This metric is computed by prompting an LLM multiple times, and thus requires additional LLM calls to compute, which may impact usage and billing.
</Note>

## Differentiating from Context Adherence

It's important to understand the distinction between related metrics:
- **Instruction Adherence** measures whether the response follows the instructions in your prompt template
- **Context Adherence** measures whether the response adheres to the context provided (e.g., your retrieved documents)

## Optimizing Your AI System

### Addressing Low Instruction Adherence

When a response has a low Instruction Adherence score, the model likely ignored its instructions. To improve your system:

1. **Flag and examine non-compliant responses**: Identify patterns in responses that don't follow instructions
2. **Experiment with prompt engineering**: Test different prompt formulations to find versions the model is more likely to adhere to
3. **Implement guardrails**: Take precautionary measures to prevent non-compliant responses from reaching end users
4. **Consider model selection**: Some models may be better at following instructions than others

## Best Practices

<CardGroup cols={2}>
  <Card title="Clarify Instructions" icon="pen-to-square">
    Write clear, specific instructions without ambiguity or contradictions to improve adherence rates.
  </Card>
  <Card title="Prioritize Critical Instructions" icon="list-check">
    Place the most important instructions prominently in your prompt and consider repeating them for emphasis.
  </Card>
  <Card title="Monitor Across Models" icon="chart-line">
    Compare Instruction Adherence scores across different LLMs to identify which models best follow your specific instructions.
  </Card>
  <Card title="Implement Feedback Loops" icon="rotate">
    Use low-adherence examples to refine your prompts and create test cases for future prompt iterations.
  </Card>
</CardGroup>

<Note>
When optimizing for Instruction Adherence, balance strict adherence with allowing the model some flexibility. Overly rigid instructions may limit the model's ability to provide helpful responses in edge cases.
</Note>