---
title: Comparing Galileo's Native Metrics
description: Explore Galileo's comprehensive metrics framework for evaluating and improving AI system performance across multiple dimensions.
---

# Galileo's Out-of-the-Box Metrics

Galileo provides a comprehensive suite of pre-built metrics designed to evaluate various aspects of AI system performance without requiring custom implementation. These metrics span across categories including Response Quality, Agentic capabilities, Safety and Compliance, and Expression and Readability. Each metric addresses specific evaluation needs, from measuring factual correctness to detecting potential biases or tracking tool usage effectiveness. The table below outlines all available native metrics, their purposes, and practical use cases to help you select the right measurements for your AI applications.

import { MetricComparisonTable } from "/snippets/components/MetricComparisonTable.mdx";

<MetricComparisonTable />