---
title: Metrics Overview
description: Explore Galileo's comprehensive metrics framework for evaluating and improving AI system performance across multiple dimensions.
---

import { MetricCategories } from "/snippets/components/Metric-categories.mdx";
import { ResponseQuality } from "/snippets/components/Response-Quality-Metrics.mdx";
import { SafetyAndComplianceMetrics } from "/snippets/components/Safety-And-Compliance-Metrics.mdx";
import { AgenticPerformanceMetrics } from "/snippets/components/Agentic-Performance-Metrics.mdx";
import { ModelConfidenceMetrics } from "/snippets/components/Model-Confidence-Metrics.mdx";
import { ExpressionAndReadabilityMetrics } from "/snippets/components/Expression-And-Readability-Metrics.mdx";


<script>
  {`
  function highlightSection() {
    // Remove any existing highlights
    const prevHighlight = document.querySelector('.section-highlight');
    if (prevHighlight) {
      prevHighlight.classList.remove('section-highlight');
    }

    // If we have a hash, find and highlight the section
    if (window.location.hash) {
      const targetSection = document.querySelector(window.location.hash);
      if (targetSection) {
        targetSection.classList.add('section-highlight');
        // Ensure smooth scroll
        targetSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
      }
    }
  }

  // Run on page load and when hash changes
  if (typeof window !== 'undefined') {
    window.addEventListener('load', highlightSection);
    window.addEventListener('hashchange', highlightSection);
  }
`}
</script>

<style>
  {`
  .section-highlight {
    position: relative;
    background: #4a2ff911;
    padding: 24px;
    margin: -24px;
    border-radius: 8px;
    border-left: 4px solid #4a2ff9;
    animation: flashHighlight 2s ease-out;
  }

  @keyframes flashHighlight {
    0% { background: #4a2ff933; }
    100% { background: #4a2ff911; }
  }
`}
</style>

Galileo provides a robust set of metrics to evaluate and improve your AI systems across multiple dimensions. These metrics help you identify issues, understand performance patterns, and implement targeted improvements to enhance your AI applications.

To calculate metrics, you will need to configure an integration with an LLM. Visit the relevant API platform to obtain an API key, then add it using the [integrations page](https://app.galileo.ai/settings/integrations) from within the Galileo console.

## Out-of-the-Box Metric Categories

Our metrics are organized into five key categories, each addressing a specific aspect of AI system performance:

  <MetricCategories />

## Response Quality Metrics

These metrics help you understand how well your AI system is responding to user queries:

  <ResponseQuality />

## Safety and Compliance Metrics

These metrics help identify potential risks and compliance issues:

<SafetyAndComplianceMetrics />

## Model Confidence Metrics

These metrics help you understand the model's certainty in its responses:

<ModelConfidenceMetrics />

## Agentic Performance Metrics

These metrics are specifically designed for AI agents that use tools:

<AgenticPerformanceMetrics />

## Expression and Readability Metrics

These metrics assess the linguistic quality of AI-generated content:

<ExpressionAndReadabilityMetrics />

## Using Metrics Effectively

To get the most value from Galileo's metrics:

1. **Start with key metrics** - Focus on metrics most relevant to your use case
2. **Establish baselines** - Understand your current performance before making changes
3. **Track trends over time** - Monitor how metrics change as you iterate on your system
4. **Combine multiple metrics** - Look at related metrics together for a more complete picture
5. **Set thresholds** - Define acceptable ranges for critical metrics

## Next Steps

<CardGroup cols={2}>
  <Card title="Explore Response Quality" href="/concepts/metrics/response-quality/instruction-adherence">
    Dive deeper into metrics for evaluating response quality.

</Card>
</CardGroup>
