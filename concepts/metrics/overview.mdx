---
title: Metrics Overview
description: Explore Galileo's comprehensive metrics framework for evaluating and improving AI system performance across multiple dimensions.
---

import { MetricCategories } from "/snippets/components/Metric-categories.mdx";
import { ResponseQuality } from "/snippets/components/Response-Quality-Metrics.mdx";
import { SafetyAndComplianceMetrics } from "/snippets/components/Safety-And-Compliance-Metrics.mdx";
import { AgenticPerformanceMetrics } from "/snippets/components/Agentic-Performance-Metrics.mdx";
import { ModelConfidenceMetrics } from "/snippets/components/Model-Confidence-Metrics.mdx";
import { ExpressionAndReadabilityMetrics } from "/snippets/components/Expression-And-Readability-Metrics.mdx";


<script>
  {`
  function highlightSection() {
    // Remove any existing highlights
    const prevHighlight = document.querySelector('.section-highlight');
    if (prevHighlight) {
      prevHighlight.classList.remove('section-highlight');
    }

    // If we have a hash, find and highlight the section
    if (window.location.hash) {
      const targetSection = document.querySelector(window.location.hash);
      if (targetSection) {
        targetSection.classList.add('section-highlight');
        // Ensure smooth scroll
        targetSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
      }
    }
  }

  // Run on page load and when hash changes
  if (typeof window !== 'undefined') {
    window.addEventListener('load', highlightSection);
    window.addEventListener('hashchange', highlightSection);
  }
`}
</script>

<style>
  {`
  .section-highlight {
    position: relative;
    background: #4a2ff911;
    padding: 24px;
    margin: -24px;
    border-radius: 8px;
    border-left: 4px solid #4a2ff9;
    animation: flashHighlight 2s ease-out;
  }

  @keyframes flashHighlight {
    0% { background: #4a2ff933; }
    100% { background: #4a2ff911; }
  }
`}
</style>

Galileo comes with a set of ready-to-use metrics that allow you to see how your AI is performing. With these metrics, you can quickly spot problems, track improvements, and make your AI work better for your users.

To calculate metrics, you will need to configure an integration with an LLM. Connect Galileo to your language model by adding your API key on the [integrations page](https://app.galileo.ai/settings/integrations) from within the Galileo application.  

## Out-of-the-Box Metric Categories

Our metrics can be broken down into five key categories, each addressing a specific aspect of AI system performance. Many times, folks benefit from using metrics from more than one category, depending on the metrics that matter most to them.  Galileo also supports custom metrics that are able to be implemented alongside the out-of-the-box metric options. 

  <MetricCategories />

## Response Quality Metrics

Use these metrics to evaluate how well your AI answers user questions and follows instructions. They’re especially helpful when you want to ensure your system is providing accurate, complete, and relevant responses.

  <ResponseQuality />

## Safety and Compliance Metrics

Use these metrics to identify potential risks, harmful content, or compliance issues in your AI’s responses. They’re important when you need to protect users, meet regulatory requirements, or avoid generating biased or unsafe content.

<SafetyAndComplianceMetrics />

## Model Confidence Metrics

Use these metrics to understand how certain or uncertain your AI model is about its answers. They’re useful when you want to flag low-confidence responses for review or improve your system’s reliability.

<ModelConfidenceMetrics />

## Agentic Performance Metrics

Use these metrics to evaluate how well your AI agents use tools, make decisions, and accomplish multi-step tasks. They’re a good fit when you’re building agents that need to interact with external systems or complete complex workflows.

<AgenticPerformanceMetrics />

## Expression and Readability Metrics

Use these metrics to assess the style, tone, and clarity of your AI’s generated content. They’re helpful when you want your AI to communicate clearly, match your brand’s voice, or produce content that’s easy for users to understand.

<ExpressionAndReadabilityMetrics />

## Using Metrics Effectively

To get the most value from Galileo's metrics:

1. **Start with key metrics** - Focus on metrics most relevant to your use case
2. **Establish baselines** - Understand your current performance before making changes
3. **Track trends over time** - Monitor how metrics change as you iterate on your system
4. **Combine multiple metrics** - Look at related metrics together for a more complete picture
5. **Set thresholds** - Define acceptable ranges for critical metrics

## Next Steps

<CardGroup cols={2}>
  <Card title="Explore Response Quality" href="/concepts/metrics/response-quality/instruction-adherence">
    Dive deeper into metrics for evaluating response quality.

</Card>
</CardGroup>
