---
title: Expression and Readability Metrics 
description: Assess the style, tone, and clarity of your AI's generated content using Galileo's expression and readability metrics.
---

# Expression and Readability Metrics Overview

Expression and readability metrics help you evaluate how well your AI communicates—not just what it says, but how it says it. These metrics are important when you want your AI to produce content that is clear, on-brand, and easy for users to understand.

Use these metrics when you want to:
- Ensure your AI's responses match your brand's voice and tone.
- Check that generated content is clear, concise, and appropriate for your audience.
- Quantitatively measure the quality of generated text compared to human-written references.

Our expression and readability metrics include:

- **Tone:** Evaluates the emotional tone and style of the response.  
  [Learn more →](/concepts/metrics/expression-and-readability/tone)
- **BLEU & ROUGE:** Standard NLP metrics for evaluating text generation quality.  
  [Learn more →](/concepts/metrics/expression-and-readability/bleu-and-rouge)

Below is a quick reference table of all expression and readability metrics:

<ExpressionAndReadabilityMetrics />

---

## Next Steps

- [Back to Metrics Overview](/concepts/metrics/overview)
- [Compare all metrics](/concepts/metrics/metric-comparison)
