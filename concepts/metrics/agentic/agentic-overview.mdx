---
title: Agentic Metrics 
description: Understand and evaluate the performance of AI agents using Galileo's agentic metrics.
---

# Agentic Metrics Overview

Agentic metrics help you measure how well your AI agents perform complex, multi-step tasks—especially when those agents need to use tools, make decisions, or interact with external systems. These metrics and helpful for those for anyone building advanced AI assistants, workflow automation, or any system where the AI acts on behalf of a user.

Use agentic metrics when you want to:
- Track whether your agent is making meaningful progress toward its goals.
- Detect and diagnose errors that occur when your agent uses tools or APIs.
- Ensure your agent is choosing the best tools or actions for each situation.

Our agentic metrics fall into three main categories:

1.  **Action Advancement:** Measures how effectively each action moves the agent closer to its goal.  
  [Learn more →](./action-advancement.mdx)
2.  **Tool Error:** Detects when an agent encounters errors or failures while using tools.  
  [Learn more →](./tool-error.mdx)
3. **Tool Selection Quality:** Evaluates whether the agent is choosing the most appropriate tools for the task at hand.  
  [Learn more →](./tool-selection-quality.mdx)

Below is a quick reference table of all agentic performance metrics:

<AgenticPerformanceMetrics />

---

## Next Steps

- [See examples of agentic metrics in action](../../cookbooks/features/experimentation/)
- [Back to Metrics Overview](../overview.mdx)
- [Compare all metrics](../metric-comparison.mdx)