
title: Spans
description: Building Blocks of Traces in Galileo
---

**Spans** in Galileo are the fundamental building blocks of traces, representing discrete operations or units of work within your AI application. A span captures a single step in your application's workflow, such as an LLM call, a document retrieval operation, a tool execution, or any other distinct process.

Each span records detailed information about a specific operation, including its inputs, outputs, duration, and any relevant metadata. Spans are organized hierarchically within traces, allowing you to understand both individual operations and their relationships to each other.

### The Role of Spans in Representing Units of Work

Spans serve several critical roles in the Galileo platform:

1. **Granular Representation**: Spans break down complex workflows into discrete, manageable units, making it easier to understand and analyze each step.

2. **Contextual Information**: Each span contains rich contextual information about the operation it represents, including inputs, outputs, and configuration details.

3. **Hierarchical Organization**: Spans can be nested within other spans, creating a hierarchical structure that reflects the organization of your application's workflows.

4. **Performance Tracking**: Spans capture timing information, allowing you to identify bottlenecks and optimize performance.

5. **Error Isolation**: When issues occur, spans help isolate the specific operation where the error originated.

### How Spans Contribute to System Evaluation and Debugging

Spans are essential for detailed system evaluation and debugging for several reasons:

1. **Pinpoint Precision**: Spans allow you to pinpoint exactly where in a workflow issues are occurring, rather than just knowing that something went wrong.

2. **Input-Output Analysis**: By examining the inputs and outputs of each span, you can identify where unexpected results are being generated.

3. **Performance Profiling**: Span durations help you identify which operations are taking the most time, guiding optimization efforts.

4. **Error Context**: When errors occur, spans provide the context needed to understand what led to the error and how to fix it.

5. **Quality Assessment**: Spans enable evaluation of individual components of your system, helping you identify which parts are performing well and which need improvement.

## Key Components of a Span

A span in Galileo consists of several core components:

### Essential Components

1. **Input**: The data or query provided to the operation
2. **Output**: The response or result generated by the operation
3. **Span Type**: The type of operation (e.g., llm, workflow, retriever, tool)
4. **Duration**: The time taken to complete the operation
5. **Timestamp**: When the operation occurred
6. **Parent Span**: The span that contains this span (if applicable)
7. **Child Spans**: Spans contained within this span (if applicable)

### Span Types and Their Behavior

Galileo supports several types of spans, each designed to capture different kinds of operations:

1. **LLM Spans**: Capture interactions with language models, including:
   - Prompts sent to the model
   - Responses received from the model
   - Model configuration (e.g., model name, temperature)
   - Token usage and other performance metrics

2. **Workflow Spans**: Represent logical groupings of operations that can contain child spans, useful for:
   - Organizing complex processes
   - Creating hierarchical structures
   - Grouping related operations

3. **Retriever Spans**: Record document retrieval operations, including:
   - Search queries
   - Retrieved documents
   - Relevance scores
   - Retrieval configuration

4. **Tool Spans**: Document tool calls in agent-based systems, including:
   - Tool inputs
   - Tool outputs
   - Error information (if applicable)
   - Tool configuration

Each span type has specific fields and behaviors tailored to the operation it represents, allowing for more detailed and relevant information capture.

### The Role of Metadata in Spans

Metadata enhances the traceability and utility of spans in several ways:

1. **Contextual Information**: Metadata provides additional context about the operation, such as user IDs, session information, or application-specific data.

2. **Filtering and Searching**: Metadata can be used to filter and search for specific spans, making it easier to find relevant information.

3. **Correlation**: Metadata helps correlate spans across different traces or systems, enabling end-to-end visibility.

4. **Custom Attributes**: You can add custom attributes to metadata to capture information specific to your application or use case.

5. **Debugging Context**: In debugging scenarios, metadata can provide crucial context about the state of your application when the operation occurred.

## Creating and Managing Spans

Galileo provides several methods for creating and managing spans, each offering different levels of control and convenience.

### Using the Galileo SDK

<CodeGroup>
```python Python
from galileo import GalileoLogger

# Initialize the logger
logger = GalileoLogger(project="my-project", log_stream="my-log-stream")

# Start a trace
trace = logger.start_trace(input="What's the weather in San Francisco?")

# Add an LLM span
llm_span = logger.add_llm_span(
    input="What's the weather in San Francisco?",
    output="The weather in San Francisco is currently sunny with a temperature of 72°F.",
    config={"model": "gpt-4o", "temperature": 0.7}
)

# Add a retriever span
retriever_span = logger.add_retriever_span(
    input="weather San Francisco",
    documents=[
        {"content": "San Francisco weather report: Sunny, 72°F", "metadata": {"source": "weather-api"}}
    ]
)

# Add a tool span
tool_span = logger.add_tool_span(
    name="WeatherAPI",
    input={"location": "San Francisco"},
    output={"condition": "Sunny", "temperature": 72}
)

# Add a workflow span
workflow_span = logger.start_workflow_span(name="Process Weather Query")
# Add child spans to the workflow span
# ...
logger.end_workflow_span(workflow_span, output="Processed weather query successfully")

# Conclude the trace
logger.conclude(output="The weather in San Francisco is currently sunny with a temperature of 72°F.")

# Flush the trace to Galileo
logger.flush()
```

```typescript TypeScript
import { GalileoLogger } from "galileo";

// Initialize the logger
const logger = new GalileoLogger();

// Start a trace
const trace = logger.startTrace("What's the weather in San Francisco?");

// Add an LLM span
trace.logSpan(
  "What's the weather in San Francisco?",
  "The weather in San Francisco is currently sunny with a temperature of 72°F.",
  "gpt-4o",
  0.7,
  "llm"
);

// Add a retriever span
trace.logRetrieverSpan(
  "weather San Francisco",
  [
    { content: "San Francisco weather report: Sunny, 72°F", metadata: { source: "weather-api" } }
  ]
);

// Add a tool span
trace.logToolSpan(
  "WeatherAPI",
  { location: "San Francisco" },
  { condition: "Sunny", temperature: 72 }
);

// Add a workflow span
const workflowSpan = trace.startWorkflowSpan("Process Weather Query");
// Add child spans to the workflow span
// ...
workflowSpan.end("Processed weather query successfully");

// Conclude the trace
trace.conclude("The weather in San Francisco is currently sunny with a temperature of 72°F.");

// Flush the trace to Galileo
trace.flush();
```
</CodeGroup>

### Using Context Managers/Wrappers

<CodeGroup>
```python Python
from galileo import galileo_context, span_context
from galileo.openai import openai

# This will create a trace and automatically add spans for OpenAI calls
with galileo_context(project="my-project", log_stream="my-log-stream"):
    # This will create a workflow span
    with span_context(name="Process User Query", span_type="workflow"):
        # This will automatically create an LLM span
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": "What is the capital of France?"}]
        )
        
        # This will create a tool span
        with span_context(name="Database Lookup", span_type="tool"):
            # Perform database lookup
            result = lookup_database("France", "capital")
            
        print(response.choices[0].message.content)
```

```typescript TypeScript
import { withGalileo, withSpan } from "galileo";
import { wrapOpenAI } from "galileo/wrappers";
import { OpenAI } from "openai";

const openai = wrapOpenAI(new OpenAI({ apiKey: "your-api-key" }));

withGalileo({ project: "my-project", logStream: "my-log-stream" }, async () => {
  // This will create a workflow span
  return withSpan({ name: "Process User Query", spanType: "workflow" }, async () => {
    // This will automatically create an LLM span
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [{ role: "user", content: "What is the capital of France?" }],
    });
    
    // This will create a tool span
    const result = await withSpan({ name: "Database Lookup", spanType: "tool" }, async () => {
      // Perform database lookup
      return lookupDatabase("France", "capital");
    });
    
    return response.choices[0].message.content;
  });
});
```
</CodeGroup>

### Using Integration Wrappers

<CodeGroup>
```python Python
from galileo.openai import openai

# This will automatically create a trace with an LLM span for the OpenAI call
response = openai.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What is the capital of France?"}]
)
print(response.choices[0].message.content)
```

```typescript TypeScript
import { wrapOpenAI } from "galileo/wrappers";
import { OpenAI } from "openai";

const openai = wrapOpenAI(new OpenAI({ apiKey: "your-api-key" }));

// This will automatically create a trace with an LLM span for the OpenAI call
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [{ role: "user", content: "What is the capital of France?" }],
});
console.log(response.choices[0].message.content);
```
</CodeGroup>

### Required Inputs and Configurations

When creating spans, you need to provide:

- **Input**: The data being processed by the operation
- **Output** (for concluded spans): The result of the operation
- **Span Type**: The type of operation (llm, workflow, retriever, or tool)
- **Name** (for workflow and tool spans): A descriptive name for the operation

Additional optional configurations include:

- **Metadata**: Additional contextual information
- **Tags**: Labels for categorization
- **Parent Span**: The span that contains this span (if applicable)
- **Model Configuration** (for LLM spans): Details about the model used

### Customization Options

Spans can be customized in several ways:

- **Custom Metadata**: Add application-specific metadata to provide additional context
- **Custom Tags**: Add tags to categorize spans and make them easier to filter
- **Nested Spans**: Create hierarchical structures by nesting spans within other spans
- **Error Handling**: Capture and log errors for better debugging
- **Custom Span Types**: Define custom span types for application-specific operations

## Using Spans in Practice

### Common Use Cases

Spans in Galileo are valuable for a wide range of use cases:

1. **LLM Interaction Tracking**: Capture details of interactions with language models, including prompts, responses, and model configurations.

2. **RAG Pipeline Analysis**: Track each step in a retrieval-augmented generation pipeline, from document retrieval to LLM generation.

3. **Agent Workflow Monitoring**: Monitor the actions of AI agents, including tool calls and decision-making processes.

4. **Performance Profiling**: Identify bottlenecks and optimization opportunities by analyzing span durations.

5. **Error Diagnosis**: When issues occur, examine spans to understand what went wrong and why.

6. **Quality Assessment**: Evaluate the quality of individual components in your AI system.

### Representing Different Parts of a Workflow

Spans can represent various parts of a workflow:

- **LLM Spans**: Represent interactions with language models
- **Retriever Spans**: Represent document retrieval operations
- **Tool Spans**: Represent tool calls or external API interactions
- **Workflow Spans**: Represent logical groupings of operations or multi-step processes

By combining these span types, you can create a complete representation of your application's workflows, from simple LLM calls to complex multi-step processes.

### Best Practices

When working with spans, follow these best practices:

1. **Meaningful Names**: Use descriptive names for spans to make them easier to understand and analyze.

2. **Appropriate Granularity**: Create spans at an appropriate level of granularity - too fine-grained and you'll have too many spans to manage, too coarse-grained and you'll miss important details.

3. **Include Relevant Metadata**: Add metadata that will be useful for filtering, analysis, and debugging.

4. **Proper Hierarchy**: Organize spans in a logical hierarchy that reflects the structure of your application's workflows.

5. **Error Handling**: Log errors in spans to help with debugging and analysis.

6. **Complete Spans**: Always conclude spans to ensure they have both input and output information.

7. **Consistent Naming**: Use consistent naming conventions for similar spans across your application.

## Integration with the Galileo Ecosystem

### Integration with Other Components

Spans integrate seamlessly with other Galileo components:

1. **Logs**: Spans contain log data, providing structure and context for individual log entries.

2. **Traces**: Spans are organized into traces, which represent complete interactions or workflows.

3. **Metrics**: Span data feeds into metrics, allowing you to measure and monitor key aspects of your AI application.

4. **Experiments**: Spans can be used in experiments to compare different models, prompts, or configurations.

5. **Datasets**: Spans can be converted into datasets for fine-tuning or evaluation.

6. **Alerts**: Patterns in spans can trigger alerts to notify you of issues or anomalies.

### Data Flow

The typical data flow for spans in Galileo is:

1. Your application creates spans using the Galileo SDK
2. Spans are organized into traces
3. Traces are flushed to Galileo (automatically or manually)
4. Galileo processes and stores the spans
5. Spans are available for viewing, analysis, and use in other Galileo features
6. Metrics and evaluations are computed based on span data
7. Insights derived from spans inform improvements to your AI application

### Dependencies and Connections

Spans have dependencies on several Galileo components:

- **Traces**: All spans belong to a trace
- **Projects**: All spans belong to a project (via their trace)
- **Log Streams**: Spans are organized into log streams (via their trace)
- **API Keys**: Authentication is required to send spans to Galileo
- **SDK**: The Galileo SDK is used to create and send spans

## Examples and Practical Applications

### Basic Span Creation

<CodeGroup>
```python Python
from galileo import GalileoLogger

logger = GalileoLogger()

# Start a trace
trace = logger.start_trace(input="Tell me about Mars")

# Add an LLM span
logger.add_llm_span(
    input="Tell me about Mars",
    output="Mars is the fourth planet from the Sun and the second-smallest planet in the Solar System...",
    config={"model": "gpt-4o", "temperature": 0.7}
)

# Conclude the trace
logger.conclude(output="Mars is the fourth planet from the Sun...")

# Flush the trace to Galileo
logger.flush()
```

```typescript TypeScript
import { GalileoLogger } from "galileo";

const logger = new GalileoLogger();

// Start a trace
const trace = logger.startTrace("Tell me about Mars");

// Add an LLM span
trace.logSpan(
  "Tell me about Mars",
  "Mars is the fourth planet from the Sun and the second-smallest planet in the Solar System...",
  "gpt-4o",
  0.7,
  "llm"
);

// Conclude the trace
trace.conclude("Mars is the fourth planet from the Sun...");

// Flush the trace to Galileo
trace.flush();
```
</CodeGroup>

### Spans with Detailed Metadata

<CodeGroup>
```python Python
from galileo import GalileoLogger

logger = GalileoLogger()

# Start a trace with metadata
trace = logger.start_trace(
    input="What's the weather in New York?",
    metadata={"user_id": "user-123", "session_id": "session-456", "client_info": {"device": "mobile", "os": "iOS"}}
)

# Add an LLM span with detailed metadata
logger.add_llm_span(
    input="What's the weather in New York?",
    output="The weather in New York is currently cloudy with a temperature of 65°F.",
    config={"model": "gpt-4o", "temperature": 0.7},
    metadata={"request_id": "req-789", "latency_ms": 250, "token_count": {"input": 10, "output": 15}}
)

# Conclude the trace
logger.conclude(output="The weather in New York is currently cloudy with a temperature of 65°F.")

# Flush the trace to Galileo
logger.flush()
```

```typescript TypeScript
import { GalileoLogger } from "galileo";

const logger = new GalileoLogger();

// Start a trace with metadata
const trace = logger.startTrace(
  "What's the weather in New York?",
  [],
  { 
    user_id: "user-123", 
    session_id: "session-456", 
    client_info: { device: "mobile", os: "iOS" } 
  }
);

// Add an LLM span with detailed metadata
trace.logSpan(
  "What's the weather in New York?",
  "The weather in New York is currently cloudy with a temperature of 65°F.",
  "gpt-4o",
  0.7,
  "llm",
  { 
    request_id: "req-789", 
    latency_ms: 250, 
    token_count: { input: 10, output: 15 } 
  }
);

// Conclude the trace
trace.conclude("The weather in New York is currently cloudy with a temperature of 65°F.");

// Flush the trace to Galileo
trace.flush();
```
</CodeGroup>

### Multi-Span RAG Example

<CodeGroup>
```python Python
from galileo import GalileoLogger

logger = GalileoLogger()

# Start a trace for a RAG application
trace = logger.start_trace(input="What are the health benefits of meditation?")

# Start a workflow span for the retrieval process
retrieval_workflow = logger.start_workflow_span(name="Document Retrieval")

# Add a retriever span for the query
logger.add_retriever_span(
    input="health benefits meditation",
    documents=[
        {"content": "Meditation has been shown to reduce stress and anxiety...", "metadata": {"source": "health-journal.pdf"}},
        {"content": "Regular meditation practice can lower blood pressure...", "metadata": {"source": "medical-research.txt"}}
    ]
)

# End the retrieval workflow
logger.end_workflow_span(retrieval_workflow, output="Retrieved 2 documents")

# Start a workflow span for the generation process
generation_workflow = logger.start_workflow_span(name="Response Generation")

# Add an LLM span for generating the response
logger.add_llm_span(
    input="Based on these documents, what are the health benefits of meditation? Documents: [...]",
    output="Based on the research, meditation offers several health benefits including reduced stress and anxiety, lower blood pressure...",
    config={"model": "gpt-4o", "temperature": 0.3}
)

# End the generation workflow
logger.end_workflow_span(generation_workflow, output="Generated response successfully")

# Conclude the trace
logger.conclude(output="Based on the research, meditation offers several health benefits...")

# Flush the trace to Galileo
logger.flush()
```

```typescript TypeScript
import { GalileoLogger } from "galileo";

const logger = new GalileoLogger();

// Start a trace for a RAG application
const trace = logger.startTrace("What are the health benefits of meditation?");

// Start a workflow span for the retrieval process
const retrievalWorkflow = trace.startWorkflowSpan("Document Retrieval");

// Add a retriever span for the query
retrievalWorkflow.logRetrieverSpan(
  "health benefits meditation",
  [
    { content: "Meditation has been shown to reduce stress and anxiety...", metadata: { source: "health-journal.pdf" } },
    { content: "Regular meditation practice can lower blood pressure...", metadata: { source: "medical-research.txt" } }
  ]
);

// End the retrieval workflow
retrievalWorkflow.end("Retrieved 2 documents");

// Start a workflow span for the generation process
const generationWorkflow = trace.startWorkflowSpan("Response Generation");

// Add an LLM span for generating the response
generationWorkflow.logSpan(
  "Based on these documents, what are the health benefits of meditation? Documents: [...]",
  "Based on the research, meditation offers several health benefits including reduced stress and anxiety, lower blood pressure...",
  "gpt-4o",
  0.3,
  "llm"
);

// End the generation workflow
generationWorkflow.end("Generated response successfully");

// Conclude the trace
trace.conclude("Based on the research, meditation offers several health benefits...");

// Flush the trace to Galileo
trace.flush();
```
</CodeGroup>

## Next Steps

After understanding spans, you can explore these related Galileo features:

### Advanced Span Analysis

- **Span Visualization**: Use the Galileo UI to visualize spans and understand the flow of data through your application.
- **Performance Analysis**: Analyze span timing information to identify bottlenecks and opportunities for improvement.
- **Error Analysis**: Use spans to understand the root causes of errors and exceptions.

### Related Galileo Workflows

- **Trace Analysis**: Examine how spans are organized into traces to understand complete workflows.
- **Metrics**: Set up metrics based on span data to monitor key aspects of your AI application.
- **Experiments**: Use spans to compare different models, prompts, or configurations.
- **Datasets**: Convert spans into datasets for fine-tuning or evaluation.
- **Alerts**: Configure alerts based on patterns in your spans.

### Further Resources

- [Logs](/concepts/logs) - Learn more about the fundamental data contained in spans
- [Traces](/concepts/traces) - Understand how spans are organized into traces
- [Log Streams](/concepts/logstreams) - Explore how to organize spans and traces into streams
- [Projects](/concepts/projects) - Learn about the top-level organization of Galileo resources
- [Metrics](/concepts/metrics) - Discover how to measure key aspects of your AI application
- [Experiments](/concepts/experiments) - Learn how to compare different approaches


