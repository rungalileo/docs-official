---
title: Experiments Overview
description: Learn how to use datasets and experiments to improve your application.
icon: atom
---

{/_ This is a duplicate of getting-started/experiments.mdx. If you update this, please sync your changes there.
At some point the getting started version should be re-written as a separate get started guide. _/}

When you start working with your application, you'll naturally progress from basic testing to more comprehensive evaluation. This journey helps you build confidence in your application's performance and systematically improve its behavior. As you advance, you'll find that organizing your test cases into **datasets** becomes essential for effective **experimentation** - allowing you to track performance, identify patterns, and measure improvements over time.

<Steps>
  <Step title="Initial Testing">
    Run your application with simple test cases to get a feel for how it performs. This is like taking your first steps:

    - Test with straightforward, expected inputs
    - Watch how your application behaves in ideal conditions
    - Look for any immediate issues or unexpected behaviors
    - Get comfortable with your metrics and what they tell you

    This phase helps you establish a baseline for what "good" looks like.

</Step>

  <Step title="Expanding Test Coverage">
    Once you're comfortable with basic testing, it's time to broaden your horizons. This is where Galileo's dataset features become valuable:

    - Introduce more complex and varied inputs
    - Use Galileo's [datasets](/concepts/datasets) to organize and maintain test cases
    - Or bring your own dataset if you already have test data
    - Run [experiments](/concepts/experiments/running-experiments-in-console) to look for patterns in how your application handles different types of inputs

    Think of this as stress-testing your application across a wide range of scenarios.

</Step>

  <Step title="Finding and Fixing Issues">
    As you test more extensively, you'll discover areas where your application needs improvement:

    - Identify specific inputs that cause problems
    - Add these inputs to a [datasets](/concepts/datasets)
    - Look for patterns in problematic cases
    - Track how your fixes perform against these problem cases
    - Build a library of test cases for regression testing

    This systematic approach helps you not only fix issues but also prevent them from recurring.

</Step>

  <Step title="Continuous Improvement">
    Now you're in a cycle of continuous improvement:

    - Regularly run tests against your datasets
    - Monitor for new issues or patterns
    - Quickly identify when changes cause problems
    - Maintain datasets that represent your key test cases
    - Track your app's improving performance over time

    This ongoing process helps ensure your application keeps getting better while maintaining quality.

</Step>
</Steps>

## Next Steps

<Card title="Create a Dataset" icon="box" href="/concepts/datasets" horizontal>
  Learn how to create and manage datasets in Galileo.

</Card>

<Card title="Run an Experiment in the Console" icon="hand-pointer" href="/concepts/experiments/running-experiments-in-console" horizontal>
  Learn how to run experiments in the Galileo Console.

</Card>

<Card title="Run an Experiment with Code" icon="code" href="/concepts/experiments/running-experiments" horizontal>
  Learn how to run experiments in Galileo.

</Card>

<Card title="Compare Experiments with Code" icon="not-equal" href="/concepts/experiments/compare" horizontal>
  Learn how to compare experiments in Galileo.

</Card>
