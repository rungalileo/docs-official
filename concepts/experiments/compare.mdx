---
title: Compare experiments
description: Learn how to compare multiple experiment runs in Galileo
icon: not-equal
---

Once you have run some experiments, the next natural step is to compare the results of your experiments, allowing you to optimize prompts, select the best model for your use case, or tune your input data to suit your needs.

Galileo allows you to compare up to 5 different experiments, showing the difference in outputs, metrics, latency, and token usage.

## Prerequisites

To compare experiments, you will need:

- A project containing 2 or more experiments, created either from the [Galileo console](concepts/experiments/running-experiments-in-console), or in [code](concepts/experiments/running-experiments) 

## Compare experiments

Experiments can be compared from the Experiments tab in the [Galileo console](https://app.galileo.ai/). Experiments are part of a project, so select the relevant project to see the experiments tab.

1. Open the **Experiments** tab

    ![The experiments tab for a project](/images/concepts/experiments/experiments-tab.webp)

1. Select the experiments you want to compare by checking the box next to each experiment. Select between 2 and 5 experiments.

    ![The experiments tab with check boxes checked on the left of 2 experiments](/images/concepts/experiments/select-experiments.webp)

1. Select the **Compare experiments** button to open the comparison page

    ![The compare experiments button, above the rows of experiments](/images/concepts/experiments/compare-experiments-button.webp)

1. You will see the experiments side by side in the comparison page

    ![2 experiments side by side showing metrics, input prompt and output](/images/concepts/experiments/compare-2-experiments-full.webp)

### Review the comparison

The comparison shows the different metrics, inputs, and outputs of each experiment.

1. If your experiment has multiple inputs, you can 

1. The **Details** section shows the model used, and averages and totals for both the cost of each response and generating the metrics, as well as averages for the metrics.

    > Averages are calculated for experiments with multiple inputs.

    ![The details tab showing 2 experiments, one using GPT 3.5 Turbo, the other using GPT-4o mini. Each detail has averages and totals for costs, and averages for metrics](/images/concepts/experiments/details.webp)

1. The **Metrics** section shows the metrics for the currently selected input




How to compare

Multiple inputs

Metadata